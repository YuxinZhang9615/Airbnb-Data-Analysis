{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_validation.csv',low_memory=False)\n",
    "x_train = df.drop(['price_log'], axis=1)\n",
    "y_train = df['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv',low_memory=False)\n",
    "x_test = df_test.drop(['price_log'], axis=1)\n",
    "y_test = df_test['price_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "score_objective = \"neg_mean_squared_error\"\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter for GradientBoostingRegressor (max. neg_mean_squared_error):  {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100}\n",
      "Grid best score (neg_mean_squared_error):  0.12893121473309382\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=0)\n",
    "grid_values_gbr = {'n_estimators': [20,30,40,50,60,70,80,90,100], 'learning_rate' : [0.1], 'max_depth' : [1,2,3,4,5,6,7,8,9,10]}\n",
    "grid_gbr = GridSearchCV(gbr, param_grid = grid_values_gbr, scoring = score_objective, cv=5, n_jobs=16)\n",
    "grid_gbr.fit(x_train, y_train)\n",
    "print('Grid best parameter for GradientBoostingRegressor (max. {}): '.format(score_objective), grid_gbr.best_params_)\n",
    "print('Grid best score ({}): '.format(score_objective), -grid_gbr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Gradient Boosting Regressor: 0.1193\n"
     ]
    }
   ],
   "source": [
    "params_gbr = {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.1}\n",
    "clf_gbr = GradientBoostingRegressor(**params_gbr)\n",
    "clf_gbr.fit(x_train,y_train)\n",
    "mse_gbr = mean_squared_error(y_test, clf_gbr.predict(x_test))\n",
    "print(\"MSE of Gradient Boosting Regressor: %.4f\" % mse_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter SVR (max. neg_mean_squared_error):  {'cache_size': 100, 'degree': 3}\n",
      "Grid best score (neg_mean_squared_error):  0.146267839604804\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "grid_values_svr = {'degree': [3,4,5,6], 'cache_size' : [100,200,300,400]}\n",
    "grid_svr = GridSearchCV(svr, param_grid = grid_values_svr, scoring = score_objective, cv=5, n_jobs=16)\n",
    "grid_svr.fit(x_train, y_train)\n",
    "print('Grid best parameter SVR (max. {}): '.format(score_objective), grid_svr.best_params_)\n",
    "print('Grid best score ({}): '.format(score_objective), -grid_svr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of SVR: 0.1271\n"
     ]
    }
   ],
   "source": [
    "params_svr = {'degree': 3, 'cache_size': 100}\n",
    "clf_svr = SVR(**params_svr)\n",
    "clf_svr.fit(x_train,y_train)\n",
    "mse_svr = mean_squared_error(y_test, clf_svr.predict(x_test))\n",
    "print(\"MSE of SVR: %.4f\" % mse_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter AdaBoostRegressor (max. neg_mean_squared_error):  {'learning_rate': 0.1, 'n_estimators': 70}\n",
      "Grid best score (neg_mean_squared_error):  0.19478043350748722\n"
     ]
    }
   ],
   "source": [
    "abr = AdaBoostRegressor(random_state=0)\n",
    "grid_values_abr = {'n_estimators': [30,40,50,60,70,80,90], 'learning_rate' : [0.1,0.5,1.0,1.5,2.0]}\n",
    "grid_abr = GridSearchCV(abr, param_grid = grid_values_abr, scoring = score_objective, cv=5, n_jobs=16)\n",
    "grid_abr.fit(x_train, y_train)\n",
    "print('Grid best parameter AdaBoostRegressor (max. {}): '.format(score_objective), grid_abr.best_params_)\n",
    "print('Grid best score ({}): '.format(score_objective), -grid_abr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Ada Boost Regressor: 0.1314\n"
     ]
    }
   ],
   "source": [
    "params_abr = {'n_estimators': 70, 'learning_rate': 0.1}\n",
    "clf_abr = GradientBoostingRegressor(**params_abr)\n",
    "clf_abr.fit(x_train,y_train)\n",
    "mse_abr = mean_squared_error(y_test, clf_abr.predict(x_test))\n",
    "print(\"MSE of Ada Boost Regressor: %.4f\" % mse_abr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid best parameter RandomForestRegressor (max. neg_mean_squared_error):  {'max_features': 10, 'n_estimators': 100}\n",
      "Grid best score (neg_mean_squared_error):  0.13618102929841894\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(random_state=0)\n",
    "grid_values_rfr = {'n_estimators': [20,30,40,50,60,70,80,90,100], 'max_features' : [1,2,3,4,5,6,7,8,9,10]}\n",
    "grid_rfr = GridSearchCV(rfr, param_grid = grid_values_rfr, scoring = score_objective, cv=5, n_jobs=16)\n",
    "grid_rfr.fit(x_train, y_train)\n",
    "print('Grid best parameter RandomForestRegressor (max. {}): '.format(score_objective), grid_rfr.best_params_)\n",
    "print('Grid best score ({}): '.format(score_objective), -grid_rfr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Random Forest Regressor: 0.1296\n"
     ]
    }
   ],
   "source": [
    "params_rfr = {'n_estimators': 100, 'max_features': 10}\n",
    "clf_rfr = GradientBoostingRegressor(**params_rfr)\n",
    "clf_rfr.fit(x_train,y_train)\n",
    "mse_rfr = mean_squared_error(y_test, clf_rfr.predict(x_test))\n",
    "print(\"MSE of Random Forest Regressor: %.4f\" % mse_rfr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
